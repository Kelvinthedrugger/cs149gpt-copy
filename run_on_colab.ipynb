{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### use openmp branch so that\n",
        "\n",
        "result tested on this [commit](https://github.com/Kelvinthedrugger/cs149gpt-copy/tree/a2ad3f6764c5ba1c9210a9e3353380f143f7c544)\n",
        "\n",
        "avx is used (google uses x64 cpu for colab)\n",
        "\n",
        "openmp is used\n",
        "\n",
        "you only need cpu to perform this test"
      ],
      "metadata": {
        "id": "6g7jMKZCcsOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --single-branch --branch openmp https://github.com/Kelvinthedrugger/cs149gpt-copy.git"
      ],
      "metadata": {
        "id": "pNkMSe8va90Q",
        "outputId": "4df3c1fc-16b0-4c0f-b7d8-1973a3a43c43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cs149gpt-copy'...\n",
            "remote: Enumerating objects: 176, done.\u001b[K\n",
            "remote: Counting objects: 100% (76/76), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 176 (delta 68), reused 61 (delta 60), pack-reused 100 (from 1)\u001b[K\n",
            "Receiving objects: 100% (176/176), 11.97 MiB | 11.14 MiB/s, done.\n",
            "Resolving deltas: 100% (100/100), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd cs149gpt-copy"
      ],
      "metadata": {
        "id": "FkRldZZmbAYo",
        "outputId": "581e8aa9-7eb9-4e62-a20a-9d8dced3846d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/cs149gpt-copy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git branch"
      ],
      "metadata": {
        "id": "h39RFwf9bDmx",
        "outputId": "0956b01c-7417-42e5-82ca-d447936ad96a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* \u001b[32mopenmp\u001b[m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat requirements.txt"
      ],
      "metadata": {
        "id": "KHVAIKDtbEci",
        "outputId": "c60d8b81-0980-46af-e92f-d6330ea014d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch==2.1.2 --index-url https://download.pytorch.org/whl/cpu # to run module_ref.so on x86-64\n",
            "Ninja\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6jY2xpSxbHhY",
        "outputId": "718aa28d-f7ce-452e-8e38-832f18710e0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.1.2 (from -r requirements.txt (line 1))\n",
            "  Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting Ninja (from -r requirements.txt (line 2))\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->-r requirements.txt (line 1)) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->-r requirements.txt (line 1)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->-r requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->-r requirements.txt (line 1)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->-r requirements.txt (line 1)) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.2->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.2->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.2->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.2->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.2->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.2->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.2->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.2->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.2->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.2->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.2->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.1.0 (from torch==2.1.2->-r requirements.txt (line 1))\n",
            "  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2->-r requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.2->-r requirements.txt (line 1)) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.2->-r requirements.txt (line 1)) (1.3.0)\n",
            "Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Ninja, triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.3.3\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.3.3:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.3.3\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.5.0.50\n",
            "    Uninstalling nvidia-cudnn-cu12-9.5.0.50:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.5.0.50\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.4.1+cu121\n",
            "    Uninstalling torch-2.4.1+cu121:\n",
            "      Successfully uninstalled torch-2.4.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.4.1+cu121 requires torch==2.4.1, but you have torch 2.1.2 which is incompatible.\n",
            "torchvision 0.19.1+cu121 requires torch==2.4.1, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Ninja-1.11.1.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvtx-cu12-12.1.105 torch-2.1.2 triton-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git branch"
      ],
      "metadata": {
        "id": "OykpLNybccfL",
        "outputId": "32b752ff-a548-4ff7-a890-6a4d16e8a0f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* \u001b[32mmine\u001b[m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 gpt149.py part1"
      ],
      "metadata": {
        "id": "DV97JMsCbK1C",
        "outputId": "a37d2984-f115-4610-b130-d7918c2aa629",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "\n",
            "Compiling code into a PyTorch module...\n",
            "\n",
            "\n",
            "Running Part 1 Test: Naive Unfused Attention\n",
            "\n",
            "-----RUNNING REFERENCE IMPLEMENTATION-----\n",
            "\n",
            "STAGE:2024-10-19 15:53:26 4932:4932 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
            "STAGE:2024-10-19 15:53:26 4932:4932 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
            "STAGE:2024-10-19 15:53:26 4932:4932 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n",
            "manual attention == pytorch attention True\n",
            "Manual Execution Time:  0.3468148708343506 \n",
            "\n",
            "-------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                           Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
            "-------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                    aten::empty         0.03%     113.000us         0.03%     113.000us      37.667us       5.00 Mb       5.00 Mb             3  \n",
            "    REFERENCE - NAIVE ATTENTION        98.90%     343.071ms        99.96%     346.762ms     346.762ms       4.50 Mb      -1.00 Mb             1  \n",
            "                    aten::zeros         0.02%      64.000us         0.61%       2.133ms       1.067ms       4.50 Mb           0 b             2  \n",
            "                    aten::clone         0.04%     122.000us         0.41%       1.408ms     704.000us       1.00 Mb           0 b             2  \n",
            "                model_inference         0.04%     125.000us       100.00%     346.887ms     346.887ms     512.00 Kb      -4.00 Mb             1  \n",
            "                  aten::flatten         0.03%      90.000us         0.25%     857.000us     171.400us     512.00 Kb           0 b             5  \n",
            "               aten::empty_like         0.00%      17.000us         0.01%      36.000us      36.000us     512.00 Kb           0 b             1  \n",
            "            aten::empty_strided         0.02%      58.000us         0.02%      58.000us      58.000us     512.00 Kb     512.00 Kb             1  \n",
            "                    aten::zero_         0.02%      68.000us         0.57%       1.975ms     987.500us           0 b           0 b             2  \n",
            "                    aten::fill_         0.55%       1.907ms         0.55%       1.907ms     953.500us           0 b           0 b             2  \n",
            "-------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 346.887ms\n",
            "\n",
            "REFERENCE - NAIVE ATTENTION statistics\n",
            "cpu time:  346.762ms\n",
            "mem usage:  4718592 bytes\n",
            "ERROR:2024-10-19 15:53:26 4932:4932 CudaDeviceProperties.cpp:27] cudaGetDeviceCount failed with code 35\n",
            "dump REFERENCE_-_NAIVE_ATTENTION.json succeeded\n",
            "-----RUNNING STUDENT IMPLEMENTATION-----\n",
            "\n",
            "STAGE:2024-10-19 15:53:34 4932:4932 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
            "STAGE:2024-10-19 15:53:34 4932:4932 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
            "STAGE:2024-10-19 15:53:34 4932:4932 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n",
            "manual attention == pytorch attention True\n",
            "Manual Execution Time:  0.3297460079193115 \n",
            "\n",
            "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                         Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
            "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                  aten::empty         0.01%      43.000us         0.01%      43.000us      14.333us       5.00 Mb       5.00 Mb             3  \n",
            "    STUDENT - NAIVE ATTENTION        99.37%     327.707ms        99.97%     329.694ms     329.694ms       4.50 Mb      -1.00 Mb             1  \n",
            "                  aten::zeros         0.02%      51.000us         0.32%       1.065ms     532.500us       4.50 Mb           0 b             2  \n",
            "                  aten::clone         0.02%      58.000us         0.25%     826.000us     413.000us       1.00 Mb           0 b             2  \n",
            "              model_inference         0.03%      97.000us       100.00%     329.791ms     329.791ms     512.00 Kb      -4.00 Mb             1  \n",
            "                aten::flatten         0.02%      57.000us         0.18%     578.000us     115.600us     512.00 Kb           0 b             5  \n",
            "             aten::empty_like         0.00%       9.000us         0.01%      17.000us      17.000us     512.00 Kb           0 b             1  \n",
            "          aten::empty_strided         0.01%      20.000us         0.01%      20.000us      20.000us     512.00 Kb     512.00 Kb             1  \n",
            "                  aten::zero_         0.01%      25.000us         0.30%     979.000us     489.500us           0 b           0 b             2  \n",
            "                  aten::fill_         0.29%     954.000us         0.29%     954.000us     477.000us           0 b           0 b             2  \n",
            "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 329.791ms\n",
            "\n",
            "STUDENT - NAIVE ATTENTION statistics\n",
            "cpu time:  329.694ms\n",
            "mem usage:  4718592 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 gpt149.py part2"
      ],
      "metadata": {
        "id": "JFoRcJnzbU75",
        "outputId": "598e2e55-1388-4626-cdfc-6e02c99bcde2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "\n",
            "Compiling code into a PyTorch module...\n",
            "\n",
            "\n",
            "Running Part 2 Test: Unfused Attention with Blocked Matmul\n",
            "\n",
            "-----RUNNING REFERENCE IMPLEMENTATION-----\n",
            "\n",
            "STAGE:2024-10-19 15:55:22 5500:5500 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
            "STAGE:2024-10-19 15:55:22 5500:5500 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
            "STAGE:2024-10-19 15:55:22 5500:5500 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n",
            "manual attention == pytorch attention True\n",
            "Manual Execution Time:  0.2830829620361328 \n",
            "\n",
            "------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
            "------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                     aten::empty         0.03%      82.000us         0.03%      82.000us      27.333us       5.00 Mb       5.00 Mb             3  \n",
            "    REFERENCE - BLOCKED MATMUL + UNFUSED SOFTMAX        98.92%     280.095ms        99.96%     283.031ms     283.031ms       4.50 Mb      -1.00 Mb             1  \n",
            "                                     aten::zeros         0.02%      54.000us         0.60%       1.710ms     855.000us       4.50 Mb           0 b             2  \n",
            "                                     aten::clone         0.03%      91.000us         0.39%       1.102ms     551.000us       1.00 Mb           0 b             2  \n",
            "                                 model_inference         0.04%     121.000us       100.00%     283.152ms     283.152ms     512.00 Kb      -4.00 Mb             1  \n",
            "                                   aten::flatten         0.03%      87.000us         0.26%     730.000us     146.000us     512.00 Kb           0 b             5  \n",
            "                                aten::empty_like         0.00%      14.000us         0.01%      32.000us      32.000us     512.00 Kb           0 b             1  \n",
            "                             aten::empty_strided         0.02%      44.000us         0.02%      44.000us      44.000us     512.00 Kb     512.00 Kb             1  \n",
            "                                     aten::zero_         0.02%      53.000us         0.56%       1.592ms     796.000us           0 b           0 b             2  \n",
            "                                     aten::fill_         0.54%       1.539ms         0.54%       1.539ms     769.500us           0 b           0 b             2  \n",
            "------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 283.152ms\n",
            "\n",
            "REFERENCE - BLOCKED MATMUL + UNFUSED SOFTMAX statistics\n",
            "cpu time:  283.031ms\n",
            "mem usage:  4718592 bytes\n",
            "-----RUNNING STUDENT IMPLEMENTATION-----\n",
            "\n",
            "STAGE:2024-10-19 15:55:31 5500:5500 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
            "STAGE:2024-10-19 15:55:32 5500:5500 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
            "STAGE:2024-10-19 15:55:32 5500:5500 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n",
            "manual attention == pytorch attention True\n",
            "Manual Execution Time:  0.5760061740875244 \n",
            "\n",
            "----------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                          Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
            "----------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                   aten::empty         0.01%      69.000us         0.01%      69.000us      23.000us       5.00 Mb       5.00 Mb             3  \n",
            "    STUDENT - BLOCKED MATMUL + UNFUSED SOFTMAX        99.48%     573.018ms        99.99%     575.963ms     575.963ms       4.50 Mb      -1.00 Mb             1  \n",
            "                                   aten::zeros         0.01%      63.000us         0.38%       2.197ms       1.099ms       4.50 Mb           0 b             2  \n",
            "                                   aten::clone         0.01%      47.000us         0.12%     674.000us     337.000us       1.00 Mb           0 b             2  \n",
            "                               model_inference         0.01%      78.000us       100.00%     576.041ms     576.041ms     512.00 Kb      -4.00 Mb             1  \n",
            "                                 aten::flatten         0.01%      43.000us         0.08%     468.000us      93.600us     512.00 Kb           0 b             5  \n",
            "                              aten::empty_like         0.00%       8.000us         0.00%      16.000us      16.000us     512.00 Kb           0 b             1  \n",
            "                           aten::empty_strided         0.00%      16.000us         0.00%      16.000us      16.000us     512.00 Kb     512.00 Kb             1  \n",
            "                                   aten::zero_         0.00%      23.000us         0.36%       2.073ms       1.036ms           0 b           0 b             2  \n",
            "                                   aten::fill_         0.36%       2.050ms         0.36%       2.050ms       1.025ms           0 b           0 b             2  \n",
            "----------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 576.041ms\n",
            "\n",
            "STUDENT - BLOCKED MATMUL + UNFUSED SOFTMAX statistics\n",
            "cpu time:  575.963ms\n",
            "mem usage:  4718592 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 gpt149.py part3"
      ],
      "metadata": {
        "id": "dMysaxD6bXWm",
        "outputId": "b4c2e22c-e336-412d-eaac-57b121a9b880",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "\n",
            "Compiling code into a PyTorch module...\n",
            "\n",
            "\n",
            "Running Part 3 Test: Fused Attention\n",
            "\n",
            "-----RUNNING REFERENCE IMPLEMENTATION-----\n",
            "\n",
            "STAGE:2024-10-19 15:54:18 5192:5192 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
            "STAGE:2024-10-19 15:54:18 5192:5192 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
            "STAGE:2024-10-19 15:54:18 5192:5192 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n",
            "manual attention == pytorch attention True\n",
            "Manual Execution Time:  0.2828333377838135 \n",
            "\n",
            "-------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                           Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
            "-------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                    aten::empty         0.01%      31.000us         0.01%      31.000us      10.333us       1.03 Mb       1.03 Mb             3  \n",
            "                    aten::clone         0.03%      97.000us         0.38%       1.075ms     537.500us       1.00 Mb           0 b             2  \n",
            "    REFERENCE - FUSED ATTENTION        93.84%     265.451ms        99.97%     282.795ms     282.795ms     544.00 Kb      -1.00 Mb             1  \n",
            "                    aten::zeros         0.02%      48.000us         0.10%     295.000us     147.500us     544.00 Kb           0 b             2  \n",
            "                model_inference         0.03%      89.000us       100.00%     282.884ms     282.884ms     512.00 Kb     -32.00 Kb             1  \n",
            "                  aten::flatten         0.46%       1.296ms         0.86%       2.435ms       4.719us     512.00 Kb           0 b           516  \n",
            "               aten::empty_like         0.00%      12.000us         0.01%      20.000us      20.000us     512.00 Kb           0 b             1  \n",
            "            aten::empty_strided         0.02%      55.000us         0.02%      55.000us      55.000us     512.00 Kb     512.00 Kb             1  \n",
            "                    aten::zero_         0.01%      41.000us         0.08%     224.000us     112.000us           0 b           0 b             2  \n",
            "                    aten::fill_         0.06%     183.000us         0.06%     183.000us     183.000us           0 b           0 b             1  \n",
            "-------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 282.884ms\n",
            "\n",
            "REFERENCE - FUSED ATTENTION statistics\n",
            "cpu time:  282.795ms\n",
            "mem usage:  557056 bytes\n",
            "ERROR:2024-10-19 15:54:19 5192:5192 CudaDeviceProperties.cpp:27] cudaGetDeviceCount failed with code 35\n",
            "dump REFERENCE_-_FUSED_ATTENTION.json succeeded\n",
            "-----RUNNING STUDENT IMPLEMENTATION-----\n",
            "\n",
            "STAGE:2024-10-19 15:54:27 5192:5192 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
            "STAGE:2024-10-19 15:54:27 5192:5192 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
            "STAGE:2024-10-19 15:54:27 5192:5192 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n",
            "manual attention == pytorch attention True\n",
            "Manual Execution Time:  0.27328968048095703 \n",
            "\n",
            "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                         Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
            "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                  aten::empty         0.02%      45.000us         0.02%      45.000us      11.250us       1.04 Mb       1.04 Mb             4  \n",
            "                  aten::clone         0.01%      41.000us         0.25%     683.000us     341.500us       1.00 Mb           0 b             2  \n",
            "                  aten::zeros         0.02%      49.000us         0.12%     315.000us     105.000us     548.00 Kb           0 b             3  \n",
            "    STUDENT - FUSED ATTENTION        97.96%     267.766ms        99.97%     273.242ms     273.242ms     544.00 Kb      -1.00 Mb             1  \n",
            "              model_inference         0.03%      95.000us       100.00%     273.337ms     273.337ms     512.00 Kb     -32.00 Kb             1  \n",
            "                aten::flatten         0.42%       1.161ms         0.80%       2.176ms       4.217us     512.00 Kb           0 b           516  \n",
            "             aten::empty_like         0.00%       8.000us         0.00%      12.000us      12.000us     512.00 Kb           0 b             1  \n",
            "          aten::empty_strided         0.01%      26.000us         0.01%      26.000us      26.000us     512.00 Kb     512.00 Kb             1  \n",
            "                  aten::zero_         0.01%      28.000us         0.08%     225.000us      75.000us           0 b           0 b             3  \n",
            "                  aten::fill_         0.07%     197.000us         0.07%     197.000us     197.000us           0 b           0 b             1  \n",
            "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 273.337ms\n",
            "\n",
            "STUDENT - FUSED ATTENTION statistics\n",
            "cpu time:  273.242ms\n",
            "mem usage:  557056 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set Bc = Br = 16 to give a better performance\n",
        "!python3 gpt149.py part4 -bc 16 -br 16"
      ],
      "metadata": {
        "id": "7Fi3oJTRbXzH",
        "outputId": "d0b25218-b6f7-4289-9709-4194b6dd8b96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "\n",
            "Compiling code into a PyTorch module...\n",
            "\n",
            "\n",
            "Running Part 4 Test: Flash Attention\n",
            "\n",
            "-----RUNNING REFERENCE IMPLEMENTATION-----\n",
            "\n",
            "STAGE:2024-10-19 15:50:21 4159:4159 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
            "STAGE:2024-10-19 15:50:22 4159:4159 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
            "STAGE:2024-10-19 15:50:22 4159:4159 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n",
            "manual attention == pytorch attention True\n",
            "Manual Execution Time:  0.734555721282959 \n",
            "\n",
            "-------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                           Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
            "-------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                    aten::zeros         0.01%      99.000us         0.62%       4.519ms     322.786us       8.52 Mb       2.00 Kb            14  \n",
            "                    aten::empty         0.02%     112.000us         0.02%     112.000us       8.000us       8.51 Mb       8.51 Mb            14  \n",
            "                model_inference         0.05%     344.000us       100.00%     734.614ms     734.614ms     512.00 Kb     -16.19 Kb             1  \n",
            "    REFERENCE - FLASH ATTENTION        99.16%     728.466ms        99.94%     734.155ms     734.155ms     512.00 Kb      -8.00 Mb             1  \n",
            "                    aten::zero_         0.18%       1.355ms         0.76%       5.593ms       0.068us           0 b           0 b         82438  \n",
            "                    aten::fill_         0.58%       4.238ms         0.58%       4.238ms       1.413ms           0 b           0 b             3  \n",
            "-------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 734.614ms\n",
            "\n",
            "REFERENCE - FLASH ATTENTION statistics\n",
            "cpu time:  734.155ms\n",
            "mem usage:  524288 bytes\n",
            "ERROR:2024-10-19 15:50:35 4159:4159 CudaDeviceProperties.cpp:27] cudaGetDeviceCount failed with code 35\n",
            "dump REFERENCE_-_FLASH_ATTENTION.json succeeded\n",
            "-----RUNNING STUDENT IMPLEMENTATION-----\n",
            "\n",
            "STAGE:2024-10-19 15:50:45 4159:4159 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
            "STAGE:2024-10-19 15:50:45 4159:4159 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
            "STAGE:2024-10-19 15:50:45 4159:4159 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n",
            "manual attention == pytorch attention True\n",
            "Manual Execution Time:  0.29160261154174805 \n",
            "\n",
            "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                         Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
            "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                  aten::empty         0.01%      40.000us         0.01%      40.000us       3.077us       1.01 Mb       1.01 Mb            13  \n",
            "                  aten::clone         0.03%      84.000us         0.23%     661.000us     330.500us       1.00 Mb           0 b             2  \n",
            "                  aten::zeros         0.02%      58.000us         0.09%     263.000us      21.917us     528.19 Kb       2.00 Kb            12  \n",
            "              model_inference         0.06%     188.000us       100.00%     291.646ms     291.646ms     512.00 Kb     -16.25 Kb             1  \n",
            "    STUDENT - FLASH ATTENTION        99.58%     290.429ms        99.91%     291.373ms     291.373ms     512.00 Kb      -1.00 Mb             1  \n",
            "                aten::flatten         0.03%      73.000us         0.16%     479.000us      31.933us     512.00 Kb           0 b            15  \n",
            "             aten::empty_like         0.00%      13.000us         0.01%      21.000us      21.000us     512.00 Kb           0 b             1  \n",
            "          aten::empty_strided         0.01%      18.000us         0.01%      18.000us      18.000us     512.00 Kb     512.00 Kb             1  \n",
            "                  aten::zero_         0.00%      14.000us         0.06%     173.000us      14.417us          64 b          64 b            12  \n",
            "                  aten::fill_         0.05%     159.000us         0.05%     159.000us     159.000us           0 b           0 b             1  \n",
            "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 291.646ms\n",
            "\n",
            "STUDENT - FLASH ATTENTION statistics\n",
            "cpu time:  291.373ms\n",
            "mem usage:  524288 bytes\n",
            "dump STUDENT_-_FLASH_ATTENTION.json succeeded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pgp-2HtRb0hX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "scratchpad",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}